package codex

import (
	"encoding/json"
	"time"
)

// CompletionRequest configures an LLM completion call.
type CompletionRequest struct {
	// SystemPrompt sets the system message that guides the model's behavior.
	SystemPrompt string `json:"system_prompt,omitempty"`

	// Messages is the conversation history to send to the model.
	Messages []Message `json:"messages"`

	// Model specifies which model to use.
	Model string `json:"model,omitempty"`

	// MaxTokens limits the response length.
	MaxTokens int `json:"max_tokens,omitempty"`

	// Temperature controls response randomness (0.0 = deterministic, 1.0 = creative).
	Temperature float64 `json:"temperature,omitempty"`

	// Tools lists available tools the model can invoke.
	Tools []Tool `json:"tools,omitempty"`

	// Options holds provider-specific configuration not covered by standard fields.
	Options map[string]any `json:"options,omitempty"`

	// WebSearchMode overrides the client-level web search mode for this request.
	// Options: "cached", "live", "disabled"
	WebSearchMode WebSearchMode `json:"web_search_mode,omitempty"`

	// OutputSchemaPath overrides the client-level --output-schema path.
	OutputSchemaPath string `json:"output_schema_path,omitempty"`

	// OutputLastMessagePath overrides the client-level --output-last-message path.
	OutputLastMessagePath string `json:"output_last_message_path,omitempty"`

	// ConfigOverrides are applied as repeated -c key=value flags for this request.
	// Request-level overrides take precedence over client-level overrides.
	ConfigOverrides map[string]any `json:"config_overrides,omitempty"`
}

// Message is a conversation turn.
type Message struct {
	Role    Role   `json:"role"`
	Content string `json:"content"`
	Name    string `json:"name,omitempty"` // For tool results
}

// Role identifies the message sender.
type Role string

// Standard message roles.
const (
	RoleUser      Role = "user"
	RoleAssistant Role = "assistant"
	RoleTool      Role = "tool"
	RoleSystem    Role = "system"
)

// Tool defines an available tool for the LLM.
type Tool struct {
	Name        string          `json:"name"`
	Description string          `json:"description"`
	Parameters  json.RawMessage `json:"parameters"` // JSON Schema
}

// CompletionResponse is the output of a completion call.
type CompletionResponse struct {
	Content      string        `json:"content"`
	ToolCalls    []ToolCall    `json:"tool_calls,omitempty"`
	Usage        TokenUsage    `json:"usage"`
	Model        string        `json:"model"`
	FinishReason string        `json:"finish_reason"`
	Duration     time.Duration `json:"duration"`

	// Codex CLI specific fields
	SessionID string  `json:"session_id,omitempty"`
	CostUSD   float64 `json:"cost_usd,omitempty"`
	NumTurns  int     `json:"num_turns,omitempty"`
}

// ToolCall represents a tool invocation request from the LLM.
type ToolCall struct {
	ID        string          `json:"id"`
	Name      string          `json:"name"`
	Arguments json.RawMessage `json:"arguments"`
}

// TokenUsage tracks token consumption.
type TokenUsage struct {
	InputTokens  int `json:"input_tokens"`
	OutputTokens int `json:"output_tokens"`
	TotalTokens  int `json:"total_tokens"`
}

// Add calculates total tokens and adds to existing usage.
func (u *TokenUsage) Add(other TokenUsage) {
	u.InputTokens += other.InputTokens
	u.OutputTokens += other.OutputTokens
	u.TotalTokens += other.TotalTokens
}

// StreamChunk is a piece of a streaming response.
type StreamChunk struct {
	Content   string      `json:"content,omitempty"`
	ToolCalls []ToolCall  `json:"tool_calls,omitempty"`
	Usage     *TokenUsage `json:"usage,omitempty"` // Only set in final chunk
	Done      bool        `json:"done"`
	Error     error       `json:"-"` // Non-nil if streaming failed
}

// Capabilities describes what a provider natively supports.
type Capabilities struct {
	Streaming   bool     `json:"streaming"`
	Tools       bool     `json:"tools"`
	MCP         bool     `json:"mcp"`
	Sessions    bool     `json:"sessions"`
	Images      bool     `json:"images"`
	NativeTools []string `json:"native_tools"`
	ContextFile string   `json:"context_file,omitempty"`
}

// HasTool checks if a native tool is available by name.
func (c Capabilities) HasTool(name string) bool {
	for _, t := range c.NativeTools {
		if t == name {
			return true
		}
	}
	return false
}
